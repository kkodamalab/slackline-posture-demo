<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Posture Demo - iPhone Safari OK</title>
<style>
  body { margin: 0; background: #111; color: #fff; font-family: sans-serif; }
  #container { position: relative; width: 100vw; height: 100vh; overflow: hidden; }
  video, canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }
  #info {
    position: absolute; bottom: 10px; left: 10px;
    background: rgba(0,0,0,0.4); padding: 10px;
    border-radius: 6px; font-size: 18px;
  }
</style>
</head>
<body>

<div id="container">
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>
  <div id="info">Loading…</div>
</div>

<script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-core@latest"></script>
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest"></script>

<script>
(async () => {
  const video = document.getElementById("video");
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");
  const info = document.getElementById("info");

  // ★ iPhone Safari を確実に動かすカメラ設定
  let stream = null;
  try {
    stream = await navigator.mediaDevices.getUserMedia({
      video: {
        width: { ideal: 1280 },
        height: { ideal: 720 },
        facingMode: "user"   // Safari は無視しても fallback あり
      },
      audio: false
    });
  } catch (err) {
    info.textContent = "Camera blocked: " + err;
    return;
  }

  video.srcObject = stream;

  // Load MediaPipe
  const vision = await FilesetResolver.forVisionTasks(
    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@latest/wasm"
  );

  const pose = await PoseLandmarker.createFromOptions(vision, {
    baseOptions: {
      modelAssetPath:
        "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_lite/float16/1/pose_landmarker_lite.task"
    },
    runningMode: "video",
    numPoses: 1
  });

  function draw() {
    if (video.readyState < 2) {
      requestAnimationFrame(draw);
      return;
    }

    if (canvas.width !== video.videoWidth) {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
    }

    pose.detectForVideo(video, performance.now(), (result) => {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      const midX = canvas.width / 2;
      ctx.strokeStyle = "yellow";
      ctx.lineWidth = 3;
      ctx.beginPath();
      ctx.moveTo(midX, 0);
      ctx.lineTo(midX, canvas.height);
      ctx.stroke();

      if (!result.landmarks || result.landmarks.length === 0) {
        info.textContent = "Detecting…";
        return;
      }

      const lm = result.landmarks[0];

      const sx = ((lm[11].x + lm[12].x) / 2) * canvas.width;
      const sy = ((lm[11].y + lm[12].y) / 2) * canvas.height;

      const hx = ((lm[23].x + lm[24].x) / 2) * canvas.width;
      const hy = ((lm[23].y + lm[24].y) / 2) * canvas.height;

      ctx.strokeStyle = "cyan";
      ctx.lineWidth = 4;
      ctx.beginPath();
      ctx.moveTo(sx, sy);
      ctx.lineTo(hx, hy);
      ctx.stroke();

      const deviation = Math.abs(sx - midX);

      info.textContent = `Deviation: ${deviation.toFixed(1)} px`;
      info.style.background = deviation > 60 ?
        "rgba(180,0,0,0.6)" :
        "rgba(0,0,0,0.4)";
    });

    requestAnimationFrame(draw);
  }

  draw();
})();
</script>

</body>
</html>
