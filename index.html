<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="UTF-8" />
<title>Slackline Posture Demo (Tasks API)</title>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<style>
  body {
    margin: 0;
    background: #111;
    color: #fff;
    font-family: sans-serif;
    display: flex;
    flex-direction: column;
    height: 100vh;
    overflow: hidden;
  }
  #videoArea {
    position: relative;
    flex: 1 1 auto;
    width: 100%;
    background: #000;
  }
  video, canvas {
    position: absolute;
    top: 0; left: 0;
    width: 100%;
    height: 100%;
    object-fit: cover;
    transform: scaleX(-1);
  }
  #info {
    flex: 0 0 auto;
    padding: 10px;
    font-size: 16px;
    background: #222;
    line-height: 1.4;
    white-space: pre-line;
  }
</style>
</head>
<body>

<div id="videoArea">
  <video id="video" autoplay playsinline muted></video>
  <canvas id="canvas"></canvas>
</div>
<div id="info">Loading…</div>

<!-- ES Modules で Tasks API を直接 import -->
<script type="module">
  import {FilesetResolver, PoseLandmarker} from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0";

  const video  = document.getElementById("video");
  const canvas = document.getElementById("canvas");
  const ctx    = canvas.getContext("2d");
  const info   = document.getElementById("info");

  async function setupCamera() {
    const stream = await navigator.mediaDevices.getUserMedia({
      video: {
        facingMode: "user",
        width:  { ideal: 1280 },
        height: { ideal: 720 },
        aspectRatio: { ideal: 16/9 }
      },
      audio: false
    });
    video.srcObject = stream;
    return new Promise(resolve => {
      video.onloadedmetadata = () => resolve();
    });
  }

  function computeAxisAndAngle(lm) {
    const avg = (a, b) => ({
      x: (a.x + b.x) / 2,
      y: (a.y + b.y) / 2
    });

    const s = avg(lm[11], lm[12]); // 肩
    const h = avg(lm[23], lm[24]); // 腰

    return {s, h};
  }

  async function main() {
    try {
      await setupCamera();

      const vision = await FilesetResolver.forVisionTasks(
        "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm"
      );

      const poseLandmarker = await PoseLandmarker.createFromOptions(vision, {
        baseOptions: {
          modelAssetPath:
            "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_full/float16/1/pose_landmarker_full.task"
        },
        runningMode: "VIDEO",
        numPoses: 1,
        minPoseDetectionConfidence: 0.5,
        minPosePresenceConfidence: 0.5,
        minTrackingConfidence: 0.5
      });

      info.textContent = "Pose loaded. 全身が映る位置に下がってください。";

      let lastVideoTime = -1;

      function renderLoop() {
        if (video.readyState < 2) {
          requestAnimationFrame(renderLoop);
          return;
        }

        if (canvas.width !== video.videoWidth || canvas.height !== video.videoHeight) {
          canvas.width  = video.videoWidth;
          canvas.height = video.videoHeight;
        }

        if (video.currentTime === lastVideoTime) {
          requestAnimationFrame(renderLoop);
          return;
        }
        lastVideoTime = video.currentTime;

        const nowMs = performance.now();
        const result = poseLandmarker.detectForVideo(video, nowMs);

        // 背景
        ctx.save();
        ctx.scale(-1, 1);
        ctx.drawImage(video, -canvas.width, 0, canvas.width, canvas.height);
        ctx.restore();

        const midX = canvas.width / 2;
        ctx.strokeStyle = "yellow";
        ctx.lineWidth   = 3;
        ctx.beginPath();
        ctx.moveTo(midX, 0);
        ctx.lineTo(midX, canvas.height);
        ctx.stroke();

        if (!result || !result.landmarks || result.landmarks.length === 0) {
          info.textContent = "Detecting…（全身が入るよう後ろに下がってください）";
          requestAnimationFrame(renderLoop);
          return;
        }

        const lm = result.landmarks[0];
        const {s, h} = computeAxisAndAngle(lm);

        s.x *= canvas.width;  s.y *= canvas.height;
        h.x *= canvas.width;  h.y *= canvas.height;

        // 体軸線（肩→腰）
        ctx.strokeStyle = "cyan";
        ctx.lineWidth   = 4;
        ctx.beginPath();
        ctx.moveTo(s.x, s.y);
        ctx.lineTo(h.x, h.y);
        ctx.stroke();

        // 垂直に対する左右角度
        const vx = h.x - s.x;
        const vy = h.y - s.y;
        const len = Math.hypot(vx, vy) || 1;
        const nx = vx / len;
        const ny = vy / len;

        let deg = Math.acos(Math.max(-1, Math.min(1, -ny))) * 180 / Math.PI;
        if (nx > 0) deg = +deg; else deg = -deg;

        const direction = (deg > 0) ? "右" : "左";
        const deviationDeg = Math.abs(deg).toFixed(1);

        info.textContent =
          `Pose detected.\n体軸傾き: ${direction}に ${deviationDeg}°\n理想姿勢は垂直です。傾きを 0° に近づけてください。`;

        requestAnimationFrame(renderLoop);
      }

      renderLoop();
    } catch (e) {
      console.error(e);
      info.textContent = "Error: " + (e && e.message ? e.message : e);
    }
  }

  main();
</script>

</body>
</html>
