<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Posture Demo - MediaPipe</title>
<style>
  body { margin: 0; background: #111; color: #fff; font-family: sans-serif; }
  #container { position: relative; width: 100vw; height: 100vh; overflow: hidden; }
  video, canvas { position: absolute; top: 0; left: 0; width: 100%; height: 100%; }
  #info {
    position: absolute; bottom: 10px; left: 10px;
    background: rgba(0,0,0,0.4); padding: 10px;
    border-radius: 6px; font-size: 18px;
  }
</style>
</head>
<body>

<div id="container">
  <video id="video" autoplay playsinline></video>
  <canvas id="canvas"></canvas>
  <div id="info">Loading…</div>
</div>

<!-- 必須：Tasks Core -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-core@0.10.0"></script>
<!-- Vision Tasks -->
<script src="https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0"></script>

<script>
(async () => {
  const video = document.getElementById("video");
  const canvas = document.getElementById("canvas");
  const ctx = canvas.getContext("2d");
  const info = document.getElementById("info");

  // ★ iOS Safari 対応：カメラパラメータ明示
  navigator.mediaDevices.getUserMedia({
    video: { facingMode: "user", width: 720, height: 1280 }
  }).then(stream => { video.srcObject = stream; });

  // ★ wasm パスは “末尾 / ” が必須（Safariバグ回避）
  const vision = await window.FilesetResolver.forVisionTasks(
    "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.0/wasm/"
  );

  // ★ モデルは full を使用（lite は iOSで失敗例あり）
  const pose = await window.PoseLandmarker.createFromOptions(vision, {
    baseOptions: {
      modelAssetPath:
        "https://storage.googleapis.com/mediapipe-models/pose_landmarker/pose_landmarker_full/float16/1/pose_landmarker_full.task"
    },
    runningMode: "video",
    numPoses: 1
  });

  info.textContent = "Pose loaded.";

  function draw() {
    if (video.readyState < 2) {
      requestAnimationFrame(draw);
      return;
    }

    if (canvas.width !== video.videoWidth) {
      canvas.width = video.videoWidth;
      canvas.height = video.videoHeight;
    }

    pose.detectForVideo(video, performance.now(), (result) => {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

      const midX = canvas.width / 2;
      ctx.strokeStyle = "yellow";
      ctx.lineWidth = 3;
      ctx.beginPath();
      ctx.moveTo(midX, 0);
      ctx.lineTo(midX, canvas.height);
      ctx.stroke();

      if (!result.landmarks || result.landmarks.length === 0) {
        info.textContent = "Detecting...";
        return;
      }

      info.textContent = "OK";

      const lm = result.landmarks[0];

      function avg(a, b) { return { x: (a.x + b.x)/2, y: (a.y + b.y)/2 }; }

      const s = avg(lm[11], lm[12]);
      const h = avg(lm[23], lm[24]);

      s.x *= canvas.width; s.y *= canvas.height;
      h.x *= canvas.width; h.y *= canvas.height;

      ctx.strokeStyle = "cyan";
      ctx.lineWidth = 4;
      ctx.beginPath();
      ctx.moveTo(s.x, s.y);
      ctx.lineTo(h.x, h.y);
      ctx.stroke();

      const deviation = Math.abs(s.x - midX);
      info.textContent = `Deviation: ${deviation.toFixed(1)} px`;
    });

    requestAnimationFrame(draw);
  }

  draw();
})();
</script>

</body>
</html>
